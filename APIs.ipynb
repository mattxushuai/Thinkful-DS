{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting praw\n",
      "  Downloading https://files.pythonhosted.org/packages/9a/c4/b33aa84d9c5c582d2fd92cb28b7027b5b6285485a68e56c9748cd49dd95b/praw-6.1.1-py2.py3-none-any.whl (117kB)\n",
      "Collecting prawcore<2.0,>=1.0.0 (from praw)\n",
      "  Downloading https://files.pythonhosted.org/packages/76/b5/ce6282dea45cba6f08a30e25d18e0f3d33277e2c9fcbda75644b8dc0089b/prawcore-1.0.1-py2.py3-none-any.whl\n",
      "Collecting update-checker>=0.16 (from praw)\n",
      "  Downloading https://files.pythonhosted.org/packages/17/c9/ab11855af164d03be0ff4fddd4c46a5bd44799a9ecc1770e01a669c21168/update_checker-0.16-py2.py3-none-any.whl\n",
      "Collecting websocket-client>=0.54.0 (from praw)\n",
      "  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in c:\\users\\shuaix\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from prawcore<2.0,>=1.0.0->praw) (2.21.0)\n",
      "Requirement already satisfied: six in c:\\users\\shuaix\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from websocket-client>=0.54.0->praw) (1.12.0)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\users\\shuaix\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.0.0->praw) (1.24.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\shuaix\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.0.0->praw) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\shuaix\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.0.0->praw) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shuaix\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.0.0->praw) (2018.11.29)\n",
      "Installing collected packages: prawcore, update-checker, websocket-client, praw\n",
      "Successfully installed praw-6.1.1 prawcore-1.0.1 update-checker-0.16 websocket-client-0.56.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 19.0.3, however version 19.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id= '-QPCBO1YK2cTZw', \\\n",
    "                     client_secret='UOMYqpe5omSA68T98XcZ_0JMyE4' , \\\n",
    "                     user_agent='montanna', \\\n",
    "                     username='montanna-colburn', \\\n",
    "                     password='#Hazelnut1')\n",
    "subreddit = reddit.subreddit('datascience')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_subreddit = subreddit.top(limit=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":) ah0q69\n"
     ]
    }
   ],
   "source": [
    "for submission in subreddit.top(limit=1):\n",
    "    print(submission.title, submission.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_dict = { \"title\":[], \\\n",
    "                \"score\":[], \\\n",
    "                \"id\":[], \\\n",
    "               \"url\":[], \\\n",
    "                \"comms_num\": [], \\\n",
    "                \"created\": [], \\\n",
    "                \"body\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for submission in top_subreddit:\n",
    "    topics_dict[\"title\"].append(submission.title)\n",
    "    topics_dict[\"score\"].append(submission.score)\n",
    "    topics_dict[\"id\"].append(submission.id)\n",
    "    topics_dict[\"url\"].append(submission.url)\n",
    "    topics_dict[\"comms_num\"].append(submission.num_comments)\n",
    "    topics_dict[\"created\"].append(submission.created)\n",
    "    topics_dict[\"body\"].append(submission.selftext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_data = pd.DataFrame(topics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>created</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>:)</td>\n",
       "      <td>1738</td>\n",
       "      <td>ah0q69</td>\n",
       "      <td>https://i.redd.it/2qsivs4vz0b21.jpg</td>\n",
       "      <td>86</td>\n",
       "      <td>1.547778e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xkcd: Machine Learing</td>\n",
       "      <td>962</td>\n",
       "      <td>a88ejl</td>\n",
       "      <td>https://i.redd.it/5v5s8apnpl521.png</td>\n",
       "      <td>33</td>\n",
       "      <td>1.545414e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Being a recent graduate</td>\n",
       "      <td>939</td>\n",
       "      <td>at80o8</td>\n",
       "      <td>https://i.redd.it/cjputnyiezh21.jpg</td>\n",
       "      <td>173</td>\n",
       "      <td>1.550810e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Map of Data Science</td>\n",
       "      <td>922</td>\n",
       "      <td>b2q0nd</td>\n",
       "      <td>https://i.redd.it/tnvy8tjhtym21.png</td>\n",
       "      <td>65</td>\n",
       "      <td>1.552982e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Don't be this guy. (x-post from r/programmerhu...</td>\n",
       "      <td>916</td>\n",
       "      <td>ael5rz</td>\n",
       "      <td>https://i.redd.it/ptvi5zyx1l921.jpg</td>\n",
       "      <td>78</td>\n",
       "      <td>1.547170e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Everyone's reaction when I tell them what I do...</td>\n",
       "      <td>915</td>\n",
       "      <td>bbprie</td>\n",
       "      <td>https://i.redd.it/g3f6dm1eghr21.jpg</td>\n",
       "      <td>88</td>\n",
       "      <td>1.554951e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Too True</td>\n",
       "      <td>878</td>\n",
       "      <td>bh3kko</td>\n",
       "      <td>https://i.redd.it/533ec87e88u21.jpg</td>\n",
       "      <td>36</td>\n",
       "      <td>1.556189e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Thought y’all could appreciate this as well.</td>\n",
       "      <td>865</td>\n",
       "      <td>aau4jv</td>\n",
       "      <td>https://i.redd.it/xghgulb1hd721.jpg</td>\n",
       "      <td>26</td>\n",
       "      <td>1.546186e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Got a new tag!</td>\n",
       "      <td>852</td>\n",
       "      <td>baag1p</td>\n",
       "      <td>https://i.redd.it/l63nrj0ddqq21.jpg</td>\n",
       "      <td>57</td>\n",
       "      <td>1.554623e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data is useless without labels. Compliments of...</td>\n",
       "      <td>832</td>\n",
       "      <td>9t9kz4</td>\n",
       "      <td>https://i.redd.it/2vs3ll355qv11.png</td>\n",
       "      <td>22</td>\n",
       "      <td>1.541109e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3 years ago I discovered Data Science, this su...</td>\n",
       "      <td>749</td>\n",
       "      <td>aohn8w</td>\n",
       "      <td>https://i.redd.it/2n4nmw6o5df21.png</td>\n",
       "      <td>150</td>\n",
       "      <td>1.549669e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>perfect answer 😎</td>\n",
       "      <td>740</td>\n",
       "      <td>9f18t6</td>\n",
       "      <td>https://i.redd.it/2yc30ije9ol11.jpg</td>\n",
       "      <td>184</td>\n",
       "      <td>1.536728e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>But it’s significant, right?</td>\n",
       "      <td>734</td>\n",
       "      <td>ap4gzx</td>\n",
       "      <td>https://i.redd.it/j05i28e27rf21.jpg</td>\n",
       "      <td>57</td>\n",
       "      <td>1.549839e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GDPR: you can’t even make a list</td>\n",
       "      <td>709</td>\n",
       "      <td>9vihdt</td>\n",
       "      <td>https://i.redd.it/94b0wsric9x11.jpg</td>\n",
       "      <td>15</td>\n",
       "      <td>1.541777e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Yes</td>\n",
       "      <td>697</td>\n",
       "      <td>aoacek</td>\n",
       "      <td>https://pbs.twimg.com/media/Dyz6uzhU8AARfca.jpg</td>\n",
       "      <td>104</td>\n",
       "      <td>1.549612e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Visual vocabulary for designing with data</td>\n",
       "      <td>646</td>\n",
       "      <td>a3gm3u</td>\n",
       "      <td>https://i.redd.it/3yf4vpn5yg221.png</td>\n",
       "      <td>33</td>\n",
       "      <td>1.544073e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data science recruiters</td>\n",
       "      <td>638</td>\n",
       "      <td>8nl2ps</td>\n",
       "      <td>https://i.redd.it/xp9lqug9o8111.jpg</td>\n",
       "      <td>49</td>\n",
       "      <td>1.527822e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>How I went from no coding or machine learning ...</td>\n",
       "      <td>626</td>\n",
       "      <td>713hnw</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>109</td>\n",
       "      <td>1.505862e+09</td>\n",
       "      <td>TL;DR: learned a buncha shit in 20 months with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Data Scientist: \\'dādə ˈsīən(t)əst\\ (n.)</td>\n",
       "      <td>610</td>\n",
       "      <td>8hxnk9</td>\n",
       "      <td>https://i.redd.it/ov8fwgw4hnw01.png</td>\n",
       "      <td>43</td>\n",
       "      <td>1.525823e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Hey all. I'm a data scientist who gave up lear...</td>\n",
       "      <td>589</td>\n",
       "      <td>a6lq4e</td>\n",
       "      <td>https://data805.com/data-science-learning-goals/</td>\n",
       "      <td>83</td>\n",
       "      <td>1.544959e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Google Introduces New Search Engine for Findin...</td>\n",
       "      <td>521</td>\n",
       "      <td>9dcltp</td>\n",
       "      <td>https://www.searchenginejournal.com/google-int...</td>\n",
       "      <td>17</td>\n",
       "      <td>1.536221e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>This hits close to home.</td>\n",
       "      <td>519</td>\n",
       "      <td>ass30h</td>\n",
       "      <td>https://i.redd.it/sxkvab82tqh21.jpg</td>\n",
       "      <td>53</td>\n",
       "      <td>1.550718e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>newbies be like</td>\n",
       "      <td>509</td>\n",
       "      <td>80rhvh</td>\n",
       "      <td>https://i.redd.it/o4mshdf4hui01.jpg</td>\n",
       "      <td>143</td>\n",
       "      <td>1.519805e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Very useful machine learning map.</td>\n",
       "      <td>499</td>\n",
       "      <td>a8yllj</td>\n",
       "      <td>https://i.redd.it/l8y8ttmij3621.jpg</td>\n",
       "      <td>25</td>\n",
       "      <td>1.545630e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>XKCD: Curve-fitting methods and the message th...</td>\n",
       "      <td>481</td>\n",
       "      <td>9h77lb</td>\n",
       "      <td>https://xkcd.com/2048/</td>\n",
       "      <td>27</td>\n",
       "      <td>1.537407e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>How true is this?</td>\n",
       "      <td>479</td>\n",
       "      <td>b8pzss</td>\n",
       "      <td>https://i.redd.it/kb1v52pkhxp21.jpg</td>\n",
       "      <td>177</td>\n",
       "      <td>1.554273e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>just have hr write up the job description it's...</td>\n",
       "      <td>474</td>\n",
       "      <td>9q11l5</td>\n",
       "      <td>https://i.redd.it/nt9ihi201ht11.png</td>\n",
       "      <td>110</td>\n",
       "      <td>1.540127e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>A glimpse on DS programs</td>\n",
       "      <td>470</td>\n",
       "      <td>9hrxqf</td>\n",
       "      <td>https://i.redd.it/nnd8bcnbimn11.png</td>\n",
       "      <td>61</td>\n",
       "      <td>1.537578e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>On the Growing Consensus that COBOL is replaci...</td>\n",
       "      <td>462</td>\n",
       "      <td>b7wir0</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>48</td>\n",
       "      <td>1.554117e+09</td>\n",
       "      <td>April Fools!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Free Course: Learn Data Science with Python - ...</td>\n",
       "      <td>460</td>\n",
       "      <td>8qgnlw</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>47</td>\n",
       "      <td>1.528813e+09</td>\n",
       "      <td>The course was created by myself (MIT alum) an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>Beer and Data Science</td>\n",
       "      <td>88</td>\n",
       "      <td>8y14cl</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>8</td>\n",
       "      <td>1.531356e+09</td>\n",
       "      <td>Several months ago, Kaggle released a dataset ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>Lost in Data Science</td>\n",
       "      <td>86</td>\n",
       "      <td>8t000k</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>31</td>\n",
       "      <td>1.529689e+09</td>\n",
       "      <td>So I've been working as a Data Scientist for n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>How to manage a data science team in a startup</td>\n",
       "      <td>89</td>\n",
       "      <td>8bxplw</td>\n",
       "      <td>https://building.lang.ai/how-to-manage-a-data-...</td>\n",
       "      <td>3</td>\n",
       "      <td>1.523638e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>Very comprehensive blog post on how to prepare...</td>\n",
       "      <td>86</td>\n",
       "      <td>6i7xr7</td>\n",
       "      <td>https://datasciencebootcamps.com/2017/04/04/wh...</td>\n",
       "      <td>3</td>\n",
       "      <td>1.497922e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>How to use R to mine Twitter - A simple, tutor...</td>\n",
       "      <td>88</td>\n",
       "      <td>57r8aa</td>\n",
       "      <td>http://rpubs.com/Antreas93/219057</td>\n",
       "      <td>2</td>\n",
       "      <td>1.476650e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>Best website for making a data science resume.</td>\n",
       "      <td>82</td>\n",
       "      <td>adh3ps</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>77</td>\n",
       "      <td>1.546892e+09</td>\n",
       "      <td>I am trying to search a resume template for da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>Kaggle / \"work on yourself\" time as a company ...</td>\n",
       "      <td>85</td>\n",
       "      <td>acrn2p</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>32</td>\n",
       "      <td>1.546699e+09</td>\n",
       "      <td>Hi, I recently joined a startup and we have th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>How did you learn data Science by yourself ?</td>\n",
       "      <td>85</td>\n",
       "      <td>9wyaje</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>42</td>\n",
       "      <td>1.542213e+09</td>\n",
       "      <td>I have a molecular biology background and want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>Just won $500 for a data analysis project - th...</td>\n",
       "      <td>88</td>\n",
       "      <td>9aepcb</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>23</td>\n",
       "      <td>1.535309e+09</td>\n",
       "      <td>Although I only made a reddit account a month ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>My Experience as a Data Analyst Intern</td>\n",
       "      <td>83</td>\n",
       "      <td>6yklj6</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>25</td>\n",
       "      <td>1.504782e+09</td>\n",
       "      <td>**About Me**\\n\\nI am currently a candidate for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>Building a data science portfolio</td>\n",
       "      <td>84</td>\n",
       "      <td>6mm0zr</td>\n",
       "      <td>https://www.dataquest.io/blog/data-science-por...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.499807e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>Good Will Hunting your way to a Stanford under...</td>\n",
       "      <td>86</td>\n",
       "      <td>5faeq5</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>21</td>\n",
       "      <td>1.480347e+09</td>\n",
       "      <td>I just finished scraping all the required and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>For those of you that have bachelors degrees i...</td>\n",
       "      <td>85</td>\n",
       "      <td>9fv7ga</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>79</td>\n",
       "      <td>1.536983e+09</td>\n",
       "      <td>For context - I am in a social sciences major ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>Data science is science's second chance to get...</td>\n",
       "      <td>83</td>\n",
       "      <td>90wyfz</td>\n",
       "      <td>https://arxiv.org/pdf/1804.10846.pdf</td>\n",
       "      <td>10</td>\n",
       "      <td>1.532285e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>The math part of data science</td>\n",
       "      <td>85</td>\n",
       "      <td>7xz6j8</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>28</td>\n",
       "      <td>1.518821e+09</td>\n",
       "      <td>I took a couple of electives during my MBA tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>Cross-posting from r/datasets because this see...</td>\n",
       "      <td>85</td>\n",
       "      <td>7x16l6</td>\n",
       "      <td>https://data.fivethirtyeight.com/</td>\n",
       "      <td>1</td>\n",
       "      <td>1.518476e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>Production Data Science workflow</td>\n",
       "      <td>83</td>\n",
       "      <td>7pnmxf</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>10</td>\n",
       "      <td>1.515701e+09</td>\n",
       "      <td>Hello everyone!\\n\\nI am a data scientist at Sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>Absolutely blown away by this Deep Neural Netw...</td>\n",
       "      <td>80</td>\n",
       "      <td>4uv83j</td>\n",
       "      <td>http://www.whatimade.today/our-frst-reddit-bot...</td>\n",
       "      <td>6</td>\n",
       "      <td>1.469663e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>Anyone Here a Freelance Data Scientist</td>\n",
       "      <td>82</td>\n",
       "      <td>avf338</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>26</td>\n",
       "      <td>1.551312e+09</td>\n",
       "      <td>I feel like the ultimate goal would be to be y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>Where to find 'real problems' to practice data...</td>\n",
       "      <td>82</td>\n",
       "      <td>9evf1o</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>35</td>\n",
       "      <td>1.536680e+09</td>\n",
       "      <td>My background is a software engineer. I've lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>Data scientists: Whats a day at work like for ...</td>\n",
       "      <td>83</td>\n",
       "      <td>95bbgv</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>78</td>\n",
       "      <td>1.533675e+09</td>\n",
       "      <td>I joined a job as a junior data scientist but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>New project targeted at scaling and paralleliz...</td>\n",
       "      <td>83</td>\n",
       "      <td>8wuz7e</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>6</td>\n",
       "      <td>1.531015e+09</td>\n",
       "      <td>The modin project provides a concordant pandas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>Data science charity work</td>\n",
       "      <td>84</td>\n",
       "      <td>7lufne</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>26</td>\n",
       "      <td>1.514138e+09</td>\n",
       "      <td>So I was having a chat with a colleague at our...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>Some Reflections on Being Turned Down for a Lo...</td>\n",
       "      <td>81</td>\n",
       "      <td>5xtzjl</td>\n",
       "      <td>http://tdhopper.com/blog/2017/Mar/06/some-refl...</td>\n",
       "      <td>11</td>\n",
       "      <td>1.488845e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>How to Get a Data Science Job: A Ridiculously ...</td>\n",
       "      <td>83</td>\n",
       "      <td>58hgpy</td>\n",
       "      <td>http://brohrer.github.io/get_data_science_job....</td>\n",
       "      <td>29</td>\n",
       "      <td>1.477006e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>One year as a Data Scientist at Stack Overflow</td>\n",
       "      <td>83</td>\n",
       "      <td>4p0hfy</td>\n",
       "      <td>http://varianceexplained.org/r/year_data_scien...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.466479e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>When and how do you know to stop pursuing a ca...</td>\n",
       "      <td>82</td>\n",
       "      <td>bascqz</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>55</td>\n",
       "      <td>1.554750e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>How often do data scientists develop machine l...</td>\n",
       "      <td>78</td>\n",
       "      <td>ay2bd1</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>43</td>\n",
       "      <td>1.551927e+09</td>\n",
       "      <td>I recently had an interview for an entry level...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Mckinsey data science technical evaluation</td>\n",
       "      <td>82</td>\n",
       "      <td>9mucvj</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>57</td>\n",
       "      <td>1.539158e+09</td>\n",
       "      <td>Does anybody know what I should expect from th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Web scraping example using Python and Beautifu...</td>\n",
       "      <td>81</td>\n",
       "      <td>8q5qrb</td>\n",
       "      <td>https://www.interviewqs.com/blog/web_scrape</td>\n",
       "      <td>11</td>\n",
       "      <td>1.528711e+09</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  score      id  \\\n",
       "0                                                   :)   1738  ah0q69   \n",
       "1                                xkcd: Machine Learing    962  a88ejl   \n",
       "2                              Being a recent graduate    939  at80o8   \n",
       "3                                  Map of Data Science    922  b2q0nd   \n",
       "4    Don't be this guy. (x-post from r/programmerhu...    916  ael5rz   \n",
       "5    Everyone's reaction when I tell them what I do...    915  bbprie   \n",
       "6                                             Too True    878  bh3kko   \n",
       "7         Thought y’all could appreciate this as well.    865  aau4jv   \n",
       "8                                       Got a new tag!    852  baag1p   \n",
       "9    Data is useless without labels. Compliments of...    832  9t9kz4   \n",
       "10   3 years ago I discovered Data Science, this su...    749  aohn8w   \n",
       "11                                    perfect answer 😎    740  9f18t6   \n",
       "12                        But it’s significant, right?    734  ap4gzx   \n",
       "13                    GDPR: you can’t even make a list    709  9vihdt   \n",
       "14                                                 Yes    697  aoacek   \n",
       "15           Visual vocabulary for designing with data    646  a3gm3u   \n",
       "16                             Data science recruiters    638  8nl2ps   \n",
       "17   How I went from no coding or machine learning ...    626  713hnw   \n",
       "18            Data Scientist: \\'dādə ˈsīən(t)əst\\ (n.)    610  8hxnk9   \n",
       "19   Hey all. I'm a data scientist who gave up lear...    589  a6lq4e   \n",
       "20   Google Introduces New Search Engine for Findin...    521  9dcltp   \n",
       "21                            This hits close to home.    519  ass30h   \n",
       "22                                     newbies be like    509  80rhvh   \n",
       "23                   Very useful machine learning map.    499  a8yllj   \n",
       "24   XKCD: Curve-fitting methods and the message th...    481  9h77lb   \n",
       "25                                   How true is this?    479  b8pzss   \n",
       "26   just have hr write up the job description it's...    474  9q11l5   \n",
       "27                            A glimpse on DS programs    470  9hrxqf   \n",
       "28   On the Growing Consensus that COBOL is replaci...    462  b7wir0   \n",
       "29   Free Course: Learn Data Science with Python - ...    460  8qgnlw   \n",
       "..                                                 ...    ...     ...   \n",
       "470                              Beer and Data Science     88  8y14cl   \n",
       "471                               Lost in Data Science     86  8t000k   \n",
       "472     How to manage a data science team in a startup     89  8bxplw   \n",
       "473  Very comprehensive blog post on how to prepare...     86  6i7xr7   \n",
       "474  How to use R to mine Twitter - A simple, tutor...     88  57r8aa   \n",
       "475     Best website for making a data science resume.     82  adh3ps   \n",
       "476  Kaggle / \"work on yourself\" time as a company ...     85  acrn2p   \n",
       "477       How did you learn data Science by yourself ?     85  9wyaje   \n",
       "478  Just won $500 for a data analysis project - th...     88  9aepcb   \n",
       "479             My Experience as a Data Analyst Intern     83  6yklj6   \n",
       "480                  Building a data science portfolio     84  6mm0zr   \n",
       "481  Good Will Hunting your way to a Stanford under...     86  5faeq5   \n",
       "482  For those of you that have bachelors degrees i...     85  9fv7ga   \n",
       "483  Data science is science's second chance to get...     83  90wyfz   \n",
       "484                      The math part of data science     85  7xz6j8   \n",
       "485  Cross-posting from r/datasets because this see...     85  7x16l6   \n",
       "486                   Production Data Science workflow     83  7pnmxf   \n",
       "487  Absolutely blown away by this Deep Neural Netw...     80  4uv83j   \n",
       "488             Anyone Here a Freelance Data Scientist     82  avf338   \n",
       "489  Where to find 'real problems' to practice data...     82  9evf1o   \n",
       "490  Data scientists: Whats a day at work like for ...     83  95bbgv   \n",
       "491  New project targeted at scaling and paralleliz...     83  8wuz7e   \n",
       "492                          Data science charity work     84  7lufne   \n",
       "493  Some Reflections on Being Turned Down for a Lo...     81  5xtzjl   \n",
       "494  How to Get a Data Science Job: A Ridiculously ...     83  58hgpy   \n",
       "495     One year as a Data Scientist at Stack Overflow     83  4p0hfy   \n",
       "496  When and how do you know to stop pursuing a ca...     82  bascqz   \n",
       "497  How often do data scientists develop machine l...     78  ay2bd1   \n",
       "498         Mckinsey data science technical evaluation     82  9mucvj   \n",
       "499  Web scraping example using Python and Beautifu...     81  8q5qrb   \n",
       "\n",
       "                                                   url  comms_num  \\\n",
       "0                  https://i.redd.it/2qsivs4vz0b21.jpg         86   \n",
       "1                  https://i.redd.it/5v5s8apnpl521.png         33   \n",
       "2                  https://i.redd.it/cjputnyiezh21.jpg        173   \n",
       "3                  https://i.redd.it/tnvy8tjhtym21.png         65   \n",
       "4                  https://i.redd.it/ptvi5zyx1l921.jpg         78   \n",
       "5                  https://i.redd.it/g3f6dm1eghr21.jpg         88   \n",
       "6                  https://i.redd.it/533ec87e88u21.jpg         36   \n",
       "7                  https://i.redd.it/xghgulb1hd721.jpg         26   \n",
       "8                  https://i.redd.it/l63nrj0ddqq21.jpg         57   \n",
       "9                  https://i.redd.it/2vs3ll355qv11.png         22   \n",
       "10                 https://i.redd.it/2n4nmw6o5df21.png        150   \n",
       "11                 https://i.redd.it/2yc30ije9ol11.jpg        184   \n",
       "12                 https://i.redd.it/j05i28e27rf21.jpg         57   \n",
       "13                 https://i.redd.it/94b0wsric9x11.jpg         15   \n",
       "14     https://pbs.twimg.com/media/Dyz6uzhU8AARfca.jpg        104   \n",
       "15                 https://i.redd.it/3yf4vpn5yg221.png         33   \n",
       "16                 https://i.redd.it/xp9lqug9o8111.jpg         49   \n",
       "17   https://www.reddit.com/r/datascience/comments/...        109   \n",
       "18                 https://i.redd.it/ov8fwgw4hnw01.png         43   \n",
       "19    https://data805.com/data-science-learning-goals/         83   \n",
       "20   https://www.searchenginejournal.com/google-int...         17   \n",
       "21                 https://i.redd.it/sxkvab82tqh21.jpg         53   \n",
       "22                 https://i.redd.it/o4mshdf4hui01.jpg        143   \n",
       "23                 https://i.redd.it/l8y8ttmij3621.jpg         25   \n",
       "24                              https://xkcd.com/2048/         27   \n",
       "25                 https://i.redd.it/kb1v52pkhxp21.jpg        177   \n",
       "26                 https://i.redd.it/nt9ihi201ht11.png        110   \n",
       "27                 https://i.redd.it/nnd8bcnbimn11.png         61   \n",
       "28   https://www.reddit.com/r/datascience/comments/...         48   \n",
       "29   https://www.reddit.com/r/datascience/comments/...         47   \n",
       "..                                                 ...        ...   \n",
       "470  https://www.reddit.com/r/datascience/comments/...          8   \n",
       "471  https://www.reddit.com/r/datascience/comments/...         31   \n",
       "472  https://building.lang.ai/how-to-manage-a-data-...          3   \n",
       "473  https://datasciencebootcamps.com/2017/04/04/wh...          3   \n",
       "474                  http://rpubs.com/Antreas93/219057          2   \n",
       "475  https://www.reddit.com/r/datascience/comments/...         77   \n",
       "476  https://www.reddit.com/r/datascience/comments/...         32   \n",
       "477  https://www.reddit.com/r/datascience/comments/...         42   \n",
       "478  https://www.reddit.com/r/datascience/comments/...         23   \n",
       "479  https://www.reddit.com/r/datascience/comments/...         25   \n",
       "480  https://www.dataquest.io/blog/data-science-por...          1   \n",
       "481  https://www.reddit.com/r/datascience/comments/...         21   \n",
       "482  https://www.reddit.com/r/datascience/comments/...         79   \n",
       "483               https://arxiv.org/pdf/1804.10846.pdf         10   \n",
       "484  https://www.reddit.com/r/datascience/comments/...         28   \n",
       "485                  https://data.fivethirtyeight.com/          1   \n",
       "486  https://www.reddit.com/r/datascience/comments/...         10   \n",
       "487  http://www.whatimade.today/our-frst-reddit-bot...          6   \n",
       "488  https://www.reddit.com/r/datascience/comments/...         26   \n",
       "489  https://www.reddit.com/r/datascience/comments/...         35   \n",
       "490  https://www.reddit.com/r/datascience/comments/...         78   \n",
       "491  https://www.reddit.com/r/datascience/comments/...          6   \n",
       "492  https://www.reddit.com/r/datascience/comments/...         26   \n",
       "493  http://tdhopper.com/blog/2017/Mar/06/some-refl...         11   \n",
       "494  http://brohrer.github.io/get_data_science_job....         29   \n",
       "495  http://varianceexplained.org/r/year_data_scien...          5   \n",
       "496  https://www.reddit.com/r/datascience/comments/...         55   \n",
       "497  https://www.reddit.com/r/datascience/comments/...         43   \n",
       "498  https://www.reddit.com/r/datascience/comments/...         57   \n",
       "499        https://www.interviewqs.com/blog/web_scrape         11   \n",
       "\n",
       "          created                                               body  \n",
       "0    1.547778e+09                                                     \n",
       "1    1.545414e+09                                                     \n",
       "2    1.550810e+09                                                     \n",
       "3    1.552982e+09                                                     \n",
       "4    1.547170e+09                                                     \n",
       "5    1.554951e+09                                                     \n",
       "6    1.556189e+09                                                     \n",
       "7    1.546186e+09                                                     \n",
       "8    1.554623e+09                                                     \n",
       "9    1.541109e+09                                                     \n",
       "10   1.549669e+09                                                     \n",
       "11   1.536728e+09                                                     \n",
       "12   1.549839e+09                                                     \n",
       "13   1.541777e+09                                                     \n",
       "14   1.549612e+09                                                     \n",
       "15   1.544073e+09                                                     \n",
       "16   1.527822e+09                                                     \n",
       "17   1.505862e+09  TL;DR: learned a buncha shit in 20 months with...  \n",
       "18   1.525823e+09                                                     \n",
       "19   1.544959e+09                                                     \n",
       "20   1.536221e+09                                                     \n",
       "21   1.550718e+09                                                     \n",
       "22   1.519805e+09                                                     \n",
       "23   1.545630e+09                                                     \n",
       "24   1.537407e+09                                                     \n",
       "25   1.554273e+09                                                     \n",
       "26   1.540127e+09                                                     \n",
       "27   1.537578e+09                                                     \n",
       "28   1.554117e+09                                       April Fools!  \n",
       "29   1.528813e+09  The course was created by myself (MIT alum) an...  \n",
       "..            ...                                                ...  \n",
       "470  1.531356e+09  Several months ago, Kaggle released a dataset ...  \n",
       "471  1.529689e+09  So I've been working as a Data Scientist for n...  \n",
       "472  1.523638e+09                                                     \n",
       "473  1.497922e+09                                                     \n",
       "474  1.476650e+09                                                     \n",
       "475  1.546892e+09  I am trying to search a resume template for da...  \n",
       "476  1.546699e+09  Hi, I recently joined a startup and we have th...  \n",
       "477  1.542213e+09  I have a molecular biology background and want...  \n",
       "478  1.535309e+09  Although I only made a reddit account a month ...  \n",
       "479  1.504782e+09  **About Me**\\n\\nI am currently a candidate for...  \n",
       "480  1.499807e+09                                                     \n",
       "481  1.480347e+09  I just finished scraping all the required and ...  \n",
       "482  1.536983e+09  For context - I am in a social sciences major ...  \n",
       "483  1.532285e+09                                                     \n",
       "484  1.518821e+09  I took a couple of electives during my MBA tha...  \n",
       "485  1.518476e+09                                                     \n",
       "486  1.515701e+09  Hello everyone!\\n\\nI am a data scientist at Sa...  \n",
       "487  1.469663e+09                                                     \n",
       "488  1.551312e+09  I feel like the ultimate goal would be to be y...  \n",
       "489  1.536680e+09  My background is a software engineer. I've lea...  \n",
       "490  1.533675e+09  I joined a job as a junior data scientist but ...  \n",
       "491  1.531015e+09  The modin project provides a concordant pandas...  \n",
       "492  1.514138e+09  So I was having a chat with a colleague at our...  \n",
       "493  1.488845e+09                                                     \n",
       "494  1.477006e+09                                                     \n",
       "495  1.466479e+09                                                     \n",
       "496  1.554750e+09                                                     \n",
       "497  1.551927e+09  I recently had an interview for an entry level...  \n",
       "498  1.539158e+09  Does anybody know what I should expect from th...  \n",
       "499  1.528711e+09                                                     \n",
       "\n",
       "[500 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
